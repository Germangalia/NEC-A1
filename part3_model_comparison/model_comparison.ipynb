{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Model Comparison (BP, BP-F, MLR-F)\n",
    "\n",
    "In this notebook, we will compare three different models:\n",
    "1. BP: Neural Network with Back-Propagation (from Part 2, implemented from scratch)\n",
    "2. BP-F: Neural Network with Back-Propagation from a library (using scikit-learn)\n",
    "3. MLR-F: Multiple Linear Regression from scikit-learn\n",
    "\n",
    "We will evaluate these models using MSE, MAE, and MAPE metrics and visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "dataset_path = \"../dataset/shopping_behavior.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "print(f\"Dataset loaded successfully with shape: {df.shape}\")\n",
    "print(\"Dataset columns:\", df.columns.tolist())\n",
    "print(\"First few rows:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing for MLR\n",
    "# Select features and target variable\n",
    "# We'll use numerical features and one-hot encode categorical features\n",
    "\n",
    "# Identify numerical and categorical columns\n",
    "numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Remove target variable from features if it's in the numerical columns\n",
    "target_col = 'Purchase Amount (USD)'\n",
    "if target_col in numerical_cols:\n",
    "    numerical_cols.remove(target_col)\n",
    "\n",
    "print(f\"Numerical columns: {numerical_cols}\")\n",
    "print(f\"Categorical columns: {categorical_cols}\")\n",
    "\n",
    "# Separate features (X) and target variable (y)\n",
    "X = df[numerical_cols + categorical_cols]\n",
    "y = df[target_col]\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "X_encoded = pd.get_dummies(X, columns=categorical_cols, prefix=categorical_cols)\n",
    "\n",
    "print(f\"Encoded features shape: {X_encoded.shape}\")\n",
    "print(f\"Encoded features columns: {X_encoded.columns.tolist()[:10]}...\")  # Show first 10 columns\n",
    "\n",
    "# Split the dataset into training (80%) and testing (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set - X: {X_train.shape}, y: {y_train.shape}\")\n",
    "print(f\"Test set - X: {X_test.shape}, y: {y_test.shape}\")\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Features have been standardized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement Multiple Linear Regression (MLR-F) model\n",
    "mlr_model = LinearRegression()\n\n",
    "# Train the model\n",
    "print(\"Training the MLR model...\")\n",
    "mlr_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on both training and test sets\n",
    "y_train_pred_mlr = mlr_model.predict(X_train_scaled)\n",
    "y_test_pred_mlr = mlr_model.predict(X_test_scaled)\n",
    "\n",
    "print(\"MLR model predictions completed.\")\n",
    "print(f\"Training predictions shape: {y_train_pred_mlr.shape}\")\n",
    "print(f\"Test predictions shape: {y_test_pred_mlr.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement Neural Network with Back-Propagation from library (BP-F) using scikit-learn\n",
    "# Using MLPRegressor which implements neural networks with backpropagation\n",
    "bp_f_model = MLPRegressor(\n",
    "    hidden_layer_sizes=(100,),  # Default: single hidden layer with 100 neurons\n",
    "    activation='relu',         # Default activation function\n",
    "    solver='adam',             # Default solver\n",
    "    alpha=0.0001,              # L2 regularization parameter\n",
    "    batch_size='auto',         # Default: min(200, n_samples)\n",
    "    learning_rate='constant',  # Learning rate schedule\n",
    "    learning_rate_init=0.001,  # Initial learning rate\n",
    "    max_iter=200,              # Maximum number of iterations\n",
    "    shuffle=True,              # Shuffle samples in each iteration\n",
    "    random_state=42,           # For reproducible results\n",
    "    early_stopping=True,       # Stop when validation score stops improving\n",
    "    validation_fraction=0.1,   # Fraction of training data for validation\n",
    "    n_iter_no_change=10        # Number of iterations with no improvement to wait\n",
    ")\n",
    "\n",
    "# Train the BP-F model\n",
    "print(\"Training the BP-F model (MLP with scikit-learn)...\")\n",
    "bp_f_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on both training and test sets\n",
    "y_train_pred_bp_f = bp_f_model.predict(X_train_scaled)\n",
    "y_test_pred_bp_f = bp_f_model.predict(X_test_scaled)\n",
    "\n",
    "print(\"BP-F model predictions completed.\")\n",
    "print(f\"Training predictions shape: {y_train_pred_bp_f.shape}\")\n",
    "print(f\"Test predictions shape: {y_test_pred_bp_f.shape}\")\n",
    "print(f\"Number of iterations: {bp_f_model.n_iter_}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}